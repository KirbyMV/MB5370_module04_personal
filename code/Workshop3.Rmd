---
title: "Workshop3"
output: html_document
date: "2025-09-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
```
# Lengthening datasets

pivot data to make it tidy. pivot_longer() usually solves a lot of data problems by increasing the number of rows and decreasing the number of columns.

```{r}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank"
  )
```
cols specifies the columns you want to pivot
names_to names the variable stored in column names
values_to names the variable stored in the cell values
values_drop_na = TRUE can remove NAs that were created when pivoting simply because the data did not exist

```{r}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  )
```

# Pivoting longer

Create tribble
```{r}
df <- tribble(
  ~id,  ~bp1, ~bp2,
   "A",  100,  120,
   "B",  140,  115,
   "C",  120,  125
)
```

we want it to have three variables: id, measurement, value

```{r}
df |> 
  pivot_longer(
    cols = bp1:bp2,
    names_to = "measurement",
    values_to = "value"
  )
```

# Widening datasets

Helps when the observation is scattered across multiple rows.
```{r}
cms_patient_experience
```

Each organization is spread across six rows 

```{r}
cms_patient_experience |> 
  distinct(measure_cd, measure_title)
```

values_from: provide existing columns that define the values
names_from: column name

```{r}
cms_patient_experience |> 
  pivot_wider(
      names_from = measure_cd,
    values_from = prf_rate
  )
```
Need to tell it which columns have values that uniquely identify each row
```{r}
cms_patient_experience |> 
  pivot_wider(
    id_cols = starts_with("org"),
    names_from = measure_cd,
    values_from = prf_rate
  )
```

# Pivoting wider 

```{r}
df <- tribble(
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "B",        "bp1",    140,
  "B",        "bp2",    115, 
  "A",        "bp2",    120,
  "A",        "bp3",    105
)
```

```{r}
df |> 
  pivot_wider(
    names_from = measurement,
    values_from = value
  )
```
new column names: unique values of measurement
```{r}
df |> 
  distinct(measurement) |> 
  pull()
```

```{r}
df |> 
  select(-measurement, -value) |> 
  distinct()
```

pivot_wider combines these results to generate an empty dataframe
```{r}
df |> 
  select(-measurement, -value) |> 
  distinct() |> 
  mutate(x = NA, y = NA, z = NA)
```
Then it fills in all the missing values using the dta in the input.

# Exercises

Why are pivot_longer and pivot_wider not perfectly symmetrical? Consider the example:
```{r}
stocks <- tibble(
  year   = c(2015, 2015, 2016, 2016),
  half  = c(   1,    2,     1,    2),
  return = c(1.88, 0.59, 0.92, 0.17)
)
stocks %>% 
  pivot_wider(names_from = year, values_from = return) %>% 
  pivot_longer(`2015`:`2016`, names_to = "year", values_to = "return")
```
Pivoting reorders the data, so pivoting wider and then longer will reorder them.

Why does this code fail?
```{r}
table4a %>% 
  pivot_longer(c(1999, 2000), names_to = "year", values_to = "cases")
```
```{r}
table4a %>% 
  pivot_longer(cols = c("1999", "2000"), names_to = "year", values_to = "cases")
```
1999 and 2000 aren't in quotes.

Consider the sample tibble below. Do you need to make it wider or longer? What are the variables?
```{r}
preg <- tribble(
  ~pregnant, ~male, ~female,
  "yes",     NA,    10,
  "no",      20,    12
)
```
variables: sex, pregnant
4 observations
need to make it longer.

# Separating and uniting data tables

```{r}
table3
```
Need to separate rate into cases and population

```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"))
```
separate by default splits values whenever it sees a non alphanumeric character.

Could also rewrite like this:
```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"), sep = "/")
```

We ask separate to convert into better types using convert = TRUE

```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"), convert = TRUE)
```
you can also use a vector of integers to separate. can use this to separate the last two digits of each year.
```{r}
table3 %>% 
  separate(year, into = c("century", "year"), sep = 2)
```

Using unite: combine multiple columns into one

```{r}
table5 %>% 
  unite(new, century, year, sep = "")
```

# Explicit missing values

NA means absent data. Blank means implicitly absent data.
```{r}
treatment <- tribble(
  ~person,           ~treatment, ~response,
  "Derrick Whitmore", 1,         7,
  NA,                 2,         10,
  NA,                 3,         NA,
  "Katherine Burke",  1,         4
)
```

Can fill in missing values using fill

```{r}
treatment |>
  fill(everything())
```
# Fixed values

Sometimes missing values represent zero. Use coalesce to replace them.

```{r}
x <- c(1, 4, 5, 7, NA)
coalesce(x, 0)
```
Sometimes values like -99 represent missing values
```{r}
x <- c(1, 4, 5, 7, -99)
na_if(x, -99)
```

# NaN

NaN means Not a Number. Usually behaves the same as NA

```{r}
x <- c(NA, NaN)
x * 10
x == 1
is.na(x)
```

# Implicit missing values

```{r}
stocks <- tibble(
  year  = c(2020, 2020, 2020, 2020, 2021, 2021, 2021),
  qtr   = c(   1,    2,    3,    4,    2,    3,    4),
  price = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)
```

The price in the fourth quarter of 2020 is explicitly missing, because its value is NA.
The price for the first quarter of 2021 is implicitly missing, because it simply does not appear in the dataset.

Here’s another example where if we pivot stocks wider to put the quarter in the columns, both missing values become explicit:
```{r}
stocks |>
  pivot_wider(
        names_from = qtr, 
    values_from = price
  )
```

# CSV files

comma separated values. looks like this:
```{r}
Student ID,Full Name,favourite.food,mealPlan,AGE 1,Sunil Huffmann,Strawberry yoghurt,Lunch only,4 2,Barclay Lynn,French fries,Lunch only,5 3,Jayendra Lyne,N/A,Breakfast and lunch,7 4,Leon Rossini,Anchovies,Lunch only, 5,Chidiegwu Dunkel,Pizza,Breakfast and lunch,five 6,Güvenç Attila,Ice cream,Lunch only,6
```
The first row or “header row” gives the column names
The following six rows provide the data. 

Use read_csv to read it from a file into R.
example:
```{r}
? read_csv
students <- read_csv("C://data/students.csv")
```

now read it from the url
```{r}
students <- read_csv("https://pos.it/r4ds-students-csv")
```

# Practical advice

Are observations in rows?  
Are variables in columns?

Check whether data is valid

```{r}
students
```

Need to recognize N/A as NA

```{r}
students <- read_csv("https://pos.it/r4ds-students-csv", na = c("N/A", ""))

students
```
rename columns to remove spaces because otherwise you'll need to use backticks everytime

```{r}
students |> 
  rename(
    student_id = `Student ID`,
    full_name = `Full Name`
  )
```

# Exercises 

Identify what is wrong with each of the following inline CSV files. What happens when you run the code?

```{r}
read_csv("a,b\n1,2,3\n4,5,6")
```

It splits the numbers unevenly because there's only 2 columns
```{r}
read_csv("a,b,c\n1,2\n1,2,3,4")
```
There are only 3 columns so it squishes the last two numbers into the last column.

```{r}
read_csv("a,b\n\"1")
```
The quotes are wrong.
```{r}
read_csv("a,b\n1,2\na,b")
```
this one looks good if the intention is to have the column names as observations

```{r}
read_csv("a;b\n1;3")
```
It uses semicolons to separate values instead of commas.

#What is relational data?

Simply put, relational data is a collection of multiple data tables in a given dataset or in a project that are related in some ways. 
These are called relational data because the relations between these tables matter, not just the individual tables, and will even be a key source of the insights you might be able to deliver. 
Many datasets will contain multiple data tables and the combination of data in these tables will help you to answer your questions of interest.

The three families of verbs designed to work with relational data are:
1. Mutating joins - add new variables to one dataframe from matching observations in another
2. Filtering joins - filter observations from one data frame based on whether or not they match an observation in the other table
3. Set operations - treat observations as if they are set elements

```{r}
library(tidyverse)
# install.packages("nycflights13")
library(nycflights13)
```

```{r}
airlines
```
```{r}
airports
```
```{r}
planes
```
```{r}
weather
```
flights connects to planes via a single variable, tailnum.
flights connects to airlines through the carrier variable.
flights connects to airports in two ways: via origin and dest variables.
flights connects to weather via origin (the location), and year, month, day and hour (the time).

# Joining datasets

So how can we actually join together our datasets? By identifying the keys. 
A key is a variable (or set of variables) that uniquely identifies an observation. In simple cases, a single variable is sufficient to identify an observation. For example, each plane is uniquely identified by its tailnum. In other cases, multiple variables may be needed. For example, to identify an observation in weather you need five variables: year, month, day, hour, origin.

A primary key uniquely identifies an observation in its own table. For example, planes$tailnum is a primary key because it uniquely identifies each plane in the planes table.

A foreign key uniquely identifies an observation in another table. For example, flights$tailnum is a foreign key because it appears in the flights table where it matches each flight to a unique plane.

Once you’ve identified the primary keys in your tables, it’s good practice to verify that they do indeed uniquely identify each observation. One way to do that is to count() the primary keys and look for entries where n is greater than one:

```{r}
planes %>% 
  count(tailnum) %>% 
  filter(n > 1)
```
```{r}
weather %>% 
  count(year, month, day, hour, origin) %>% 
  filter(n > 1)
```
If a table lacks a primary key, it’s sometimes useful to add one with mutate() and row_number(). That makes it easier to match observations if you’ve done some filtering and want to check back in with the original data. This is called a surrogate key.

# Mutating joins

A mutating join allows you to combine variables from two tables. It first matches observations by their keys, then copies across variables from one table to the other.

Join functions (like the base mutate()) add variables to the right side of your data table so sometimes you’ll need to change the view of your screen to see them all. (Remember your tibble skills! Set your global options!) 

Create a subset of nycflights13
```{r}
flights2 <- flights %>% 
  select(year:day, hour, origin, dest, tailnum, carrier)
```
Now see what happens when we use left_join()
```{r}
flights2 %>%
  select(-origin, -dest) %>% 
  left_join(airlines, by = "carrier")
```
Could have used mutate but that requires more specifications
```{r}
flights2 %>%
  select(-origin, -dest) %>% 
  mutate(name = airlines$name[match(carrier, airlines$carrier)])
```

```{r}
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     3, "x3"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2",
     4, "y3"
)
```

inner join: matches observations with equivalent keys. Unmatched joins are not included in the result.
```{r}
x %>% 
  inner_join(y, by = "key")
```
outer join: keeps observations that appear in at least one of the tables. Three types of outer joins:
1. left_join() keeps all observations in x (we’ve seen this in our first example)
2. right_join() keeps all observations in y
3. full_join() keeps all observations in x and y

left_join should be your default join because it preserves the original observations even when there isn't a match

What happens when keys are not unique:

1. One table has duplicate keys. This is useful when you want to add in additional information as there is typically a one-to-many relationship.
```{r}
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     2, "x3",
     1, "x4"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2"
)
left_join(x, y, by = "key")
```
2. Both tables have duplicate keys. This is usually an error because in neither table do the keys uniquely identify an observation. When you join duplicate keys, you get all possible combinations, the Cartesian product:
```{r}
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     2, "x3",
     3, "x4"
)
y <- tribble(
  ~key, ~val_y,
       1, "y1",
     2, "y2",
     2, "y3",
     3, "y4"
)
left_join(x, y, by = "key")
```
you can use other values for by =  to connect tables in other ways
The default, by = NULL, uses all variables that appear in both tables, the natural join. For example, the flights and weather tables match on their common variables: year, month, day, hour and origin.
```{r}
flights2 %>% 
  left_join(weather)
```
A character vector, by = "x". This is like a natural join, but uses only some of the common variables. For example, flights and planes have year variables, but they mean different things, so we only want to join by tailnum. Note: that the year variables (which appear in both input data frames, but are not constrained to be equal) are disambiguated in the output with a suffix.
```{r}
flights2 %>% 
  left_join(planes, by = "tailnum")
```
A named character vector: by = c("a" = "b"). This will match variable a in table x to variable b in table y. The variables from x will be used in the output.
```{r}
flights2 %>% 
  left_join(airports, c("dest" = "faa"))
```
```{r}
flights2 %>% 
  left_join(airports, c("origin" = "faa"))
```

